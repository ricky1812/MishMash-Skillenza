# -*- coding: utf-8 -*-
"""german.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NmHjqIjhiaU_puoR_P4zi9GjI-30ilv6
"""





import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import random
import pandas as pd
import cv2
from keras.utils.np_utils import to_categorical

with open('german-traffic-signs/train.p','rb') as f:
  train_data = pickle.load(f)
with open('german-traffic-signs/train.p','rb') as f:
  test_data = pickle.load(f)
with open('german-traffic-signs/train.p','rb') as f:
  valid_data = pickle.load(f)

x_train , y_train = train_data['features'] ,train_data['labels']
x_test , y_test = train_data['features'] ,train_data['labels']
x_valid , y_valid = train_data['features'] ,train_data['labels']

print(x_train.shape)
print(y_train.shape)

assert(x_train.shape[0]==y_train.shape[0]),'train images not equal to train labels'
assert(x_test.shape[0]==y_test.shape[0]),'train images not equal to train labels'
assert(x_valid.shape[0]==y_valid.shape[0]),'train images not equal to train labels'

assert(x_train.shape[1:]==(32,32,3)),'image dimension must be 32 X 32 X 3'
assert(x_test.shape[1:]==(32,32,3)),'image dimension must be 32 X 32 X 3'
assert(x_valid.shape[1:]==(32,32,3)),'image dimension must be 32 X 32 X 3'

data = pd.read_csv('german-traffic-signs/signnames.csv')
data.head()

data['ClassId'].unique().shape

#x_train.shape[1:]
n_cols= 5
n_classes=43

fig,axes = plt.subplots(nrows=n_classes,ncols=n_cols,figsize=(15,50))
fig.tight_layout()

for i in range(n_cols):
  for j in range(n_classes):
    selected_images = x_train[y_train==j]
    image = selected_images[random.randint(0,(len(selected_images)-1)),:,:,:]
    axes[j][i].imshow(image)
    axes[j][i].axis=('off')
    if i ==2:
      axes[j][i].set_title(str(data.SignName[data.ClassId==j]))     #j=data.Signname[data.Classes==j]

sns.countplot(data.ClassId)
plt.show()

def grayscale(image):
  gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)
  return gray
plt.imshow(grayscale(x_train[0]),cmap='gray')
plt.show()

def equalize(image):
  image = cv2.equalizeHist(image)
  return image
img = grayscale(x_train[0])
img = equalize(img)
plt.imshow(img,cmap='gray')

def preprocess(image):
  image = equalize(grayscale(image))
  image=image/255
  return image
plt.imshow(preprocess(x_train[0]),cmap='gray')
plt.show()

x_train = np.array(list(map(preprocess,x_train)))
x_test = np.array(list(map(preprocess,x_test)))
x_valid = np.array(list(map(preprocess,x_valid)))

x_train = x_train.reshape(x_train.shape[0],32,32,1)
x_test = x_test.reshape(x_test.shape[0],32,32,1)
x_valid = x_valid.reshape(x_valid.shape[0],32,32,1)

y_train = to_categorical(y_train,43)
y_test = to_categorical(y_test,43)
y_valid = to_categorical(y_valid,43)

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,rotation_range=10,zoom_range=0.1,shear_range=0.1)

#calling the datagenerator to augment in real time
batches = datagen.flow(x_train,y_train,batch_size=20)
x_batch,y_batch = next(batches)

fig, axes = plt.subplots(1,15,figsize=(20,5))
fig.tight_layout()

for i in range(15):
  axes[i].imshow(x_batch[i].reshape(32,32),cmap='gray')
  axes[i].axis('off')

from keras.models import Sequential
from keras.layers import Dense,Dropout,Flatten
from keras.layers.convolutional import Conv2D,MaxPooling2D
from keras.optimizers import Adam

def lenet_model():
  model=Sequential()
  model.add(Conv2D(60, (5,5),input_shape=(32,32,1),activation='relu'))
  model.add(Conv2D(60, (5,5),activation='relu'))
  model.add(MaxPooling2D(pool_size=(2,2)))

  model.add(Flatten())
  model.add(Dense(500,activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(n_classes,activation='softmax'))
  model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])
  return model

model = lenet_model()
print(model.summary())

h = model.fit_generator(datagen.flow(x_train,y_train,batch_size=50),steps_per_epoch = 2000,epochs = 10,validation_data = (x_valid,y_valid),shuffle=1,verbose=1)

plt.plot(h.history['loss'],label='loss')
plt.plot(h.history['val_loss'],label='val_loss')
plt.legend()
plt.show()

plt.plot(h.history['acc'],label='acc')
plt.plot(h.history['val_acc'],label='val_acc')
plt.legend()
plt.show()

model.save("traffic_model.h5")









